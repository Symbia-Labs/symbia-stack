[
  {
    "id": "int-openai-config",
    "key": "integrations/ai/openai/config",
    "name": "OpenAI Provider Configuration",
    "description": "Configuration for OpenAI API integration",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "integration"],
    "accessPolicy": {
      "visibility": "public",
      "actions": {
        "read": { "anyOf": ["public"] },
        "write": { "anyOf": ["role:admin"] }
      }
    },
    "metadata": {
      "provider": "openai",
      "baseUrl": "https://api.openai.com/v1",
      "authType": "bearer",
      "endpoints": {
        "chat.completions": "/chat/completions",
        "embeddings": "/embeddings",
        "completions": "/completions"
      },
      "rateLimits": {
        "requestsPerMinute": 60,
        "tokensPerMinute": 40000
      },
      "defaultModel": "gpt-4o-mini",
      "supportedOperations": ["chat.completions", "embeddings"]
    }
  },
  {
    "id": "int-openai-gpt4o",
    "key": "integrations/ai/openai/models/gpt-4o",
    "name": "GPT-4o",
    "description": "OpenAI GPT-4o - multimodal flagship model with vision and audio",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "gpt-4", "multimodal"],
    "metadata": {
      "provider": "openai",
      "modelId": "gpt-4o",
      "displayName": "GPT-4o",
      "contextWindow": 128000,
      "maxOutputTokens": 16384,
      "inputPricePerMillion": 2.50,
      "outputPricePerMillion": 10.00,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["vision", "function_calling", "json_mode"]
    }
  },
  {
    "id": "int-openai-gpt4o-mini",
    "key": "integrations/ai/openai/models/gpt-4o-mini",
    "name": "GPT-4o Mini",
    "description": "OpenAI GPT-4o Mini - fast and affordable for most tasks",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "gpt-4"],
    "metadata": {
      "provider": "openai",
      "modelId": "gpt-4o-mini",
      "displayName": "GPT-4o Mini",
      "contextWindow": 128000,
      "maxOutputTokens": 16384,
      "inputPricePerMillion": 0.15,
      "outputPricePerMillion": 0.60,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["vision", "function_calling", "json_mode"]
    }
  },
  {
    "id": "int-openai-o1",
    "key": "integrations/ai/openai/models/o1",
    "name": "o1",
    "description": "OpenAI o1 - reasoning model for complex problem solving",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "reasoning"],
    "metadata": {
      "provider": "openai",
      "modelId": "o1",
      "displayName": "o1",
      "contextWindow": 200000,
      "maxOutputTokens": 100000,
      "inputPricePerMillion": 15.00,
      "outputPricePerMillion": 60.00,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["reasoning", "function_calling"]
    }
  },
  {
    "id": "int-openai-o1-mini",
    "key": "integrations/ai/openai/models/o1-mini",
    "name": "o1-mini",
    "description": "OpenAI o1-mini - fast reasoning model for coding and STEM",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "reasoning"],
    "metadata": {
      "provider": "openai",
      "modelId": "o1-mini",
      "displayName": "o1-mini",
      "contextWindow": 128000,
      "maxOutputTokens": 65536,
      "inputPricePerMillion": 3.00,
      "outputPricePerMillion": 12.00,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["reasoning", "function_calling"]
    }
  },
  {
    "id": "int-openai-o3-mini",
    "key": "integrations/ai/openai/models/o3-mini",
    "name": "o3-mini",
    "description": "OpenAI o3-mini - advanced reasoning with adaptive thinking",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "reasoning"],
    "metadata": {
      "provider": "openai",
      "modelId": "o3-mini",
      "displayName": "o3-mini",
      "contextWindow": 200000,
      "maxOutputTokens": 100000,
      "inputPricePerMillion": 1.10,
      "outputPricePerMillion": 4.40,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["reasoning", "function_calling", "adaptive_thinking"]
    }
  },
  {
    "id": "int-openai-gpt4-turbo",
    "key": "integrations/ai/openai/models/gpt-4-turbo",
    "name": "GPT-4 Turbo",
    "description": "OpenAI GPT-4 Turbo - high capability with vision support",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "openai", "model", "gpt-4"],
    "metadata": {
      "provider": "openai",
      "modelId": "gpt-4-turbo",
      "displayName": "GPT-4 Turbo",
      "contextWindow": 128000,
      "maxOutputTokens": 4096,
      "inputPricePerMillion": 10.00,
      "outputPricePerMillion": 30.00,
      "supportedOperations": ["chat.completions"],
      "capabilities": ["vision", "function_calling", "json_mode"]
    }
  },
  {
    "id": "int-openai-embedding-3-small",
    "key": "integrations/ai/openai/models/text-embedding-3-small",
    "name": "text-embedding-3-small",
    "description": "OpenAI embedding model - efficient and cost-effective",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "embedding", "openai", "model"],
    "metadata": {
      "provider": "openai",
      "modelId": "text-embedding-3-small",
      "displayName": "Embedding 3 Small",
      "dimensions": 1536,
      "maxInputTokens": 8191,
      "inputPricePerMillion": 0.02,
      "supportedOperations": ["embeddings"]
    }
  },
  {
    "id": "int-openai-embedding-3-large",
    "key": "integrations/ai/openai/models/text-embedding-3-large",
    "name": "text-embedding-3-large",
    "description": "OpenAI embedding model - highest quality embeddings",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "embedding", "openai", "model"],
    "metadata": {
      "provider": "openai",
      "modelId": "text-embedding-3-large",
      "displayName": "Embedding 3 Large",
      "dimensions": 3072,
      "maxInputTokens": 8191,
      "inputPricePerMillion": 0.13,
      "supportedOperations": ["embeddings"]
    }
  },
  {
    "id": "int-anthropic-config",
    "key": "integrations/ai/anthropic/config",
    "name": "Anthropic Provider Configuration",
    "description": "Configuration for Anthropic Claude API",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "integration"],
    "accessPolicy": {
      "visibility": "public",
      "actions": {
        "read": { "anyOf": ["public"] },
        "write": { "anyOf": ["role:admin"] }
      }
    },
    "metadata": {
      "provider": "anthropic",
      "baseUrl": "https://api.anthropic.com/v1",
      "authType": "header",
      "authHeader": "x-api-key",
      "endpoints": {
        "messages": "/messages"
      },
      "rateLimits": {
        "requestsPerMinute": 60,
        "tokensPerMinute": 40000
      },
      "defaultModel": "claude-sonnet-4-20250514",
      "supportedOperations": ["messages"]
    }
  },
  {
    "id": "int-anthropic-claude-opus-4",
    "key": "integrations/ai/anthropic/models/claude-opus-4-20250514",
    "name": "Claude Opus 4",
    "description": "Anthropic Claude Opus 4 - most capable model for complex tasks",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "model", "claude-4"],
    "metadata": {
      "provider": "anthropic",
      "modelId": "claude-opus-4-20250514",
      "displayName": "Claude Opus 4",
      "contextWindow": 200000,
      "maxOutputTokens": 32000,
      "inputPricePerMillion": 15.00,
      "outputPricePerMillion": 75.00,
      "supportedOperations": ["messages"],
      "capabilities": ["vision", "tool_use", "extended_thinking"]
    }
  },
  {
    "id": "int-anthropic-claude-sonnet-4",
    "key": "integrations/ai/anthropic/models/claude-sonnet-4-20250514",
    "name": "Claude Sonnet 4",
    "description": "Anthropic Claude Sonnet 4 - best balance of speed and capability",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "model", "claude-4"],
    "metadata": {
      "provider": "anthropic",
      "modelId": "claude-sonnet-4-20250514",
      "displayName": "Claude Sonnet 4",
      "contextWindow": 200000,
      "maxOutputTokens": 64000,
      "inputPricePerMillion": 3.00,
      "outputPricePerMillion": 15.00,
      "supportedOperations": ["messages"],
      "capabilities": ["vision", "tool_use", "extended_thinking"]
    }
  },
  {
    "id": "int-anthropic-claude-35-sonnet",
    "key": "integrations/ai/anthropic/models/claude-3-5-sonnet-20241022",
    "name": "Claude 3.5 Sonnet",
    "description": "Anthropic Claude 3.5 Sonnet - high capability at lower cost",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "model", "claude-3"],
    "metadata": {
      "provider": "anthropic",
      "modelId": "claude-3-5-sonnet-20241022",
      "displayName": "Claude 3.5 Sonnet",
      "contextWindow": 200000,
      "maxOutputTokens": 8192,
      "inputPricePerMillion": 3.00,
      "outputPricePerMillion": 15.00,
      "supportedOperations": ["messages"],
      "capabilities": ["vision", "tool_use"]
    }
  },
  {
    "id": "int-anthropic-claude-35-haiku",
    "key": "integrations/ai/anthropic/models/claude-3-5-haiku-20241022",
    "name": "Claude 3.5 Haiku",
    "description": "Anthropic Claude 3.5 Haiku - fastest model for simple tasks",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "model", "claude-3"],
    "metadata": {
      "provider": "anthropic",
      "modelId": "claude-3-5-haiku-20241022",
      "displayName": "Claude 3.5 Haiku",
      "contextWindow": 200000,
      "maxOutputTokens": 8192,
      "inputPricePerMillion": 0.80,
      "outputPricePerMillion": 4.00,
      "supportedOperations": ["messages"],
      "capabilities": ["vision", "tool_use"]
    }
  },
  {
    "id": "int-anthropic-claude-3-opus",
    "key": "integrations/ai/anthropic/models/claude-3-opus-20240229",
    "name": "Claude 3 Opus",
    "description": "Anthropic Claude 3 Opus - previous generation flagship",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "anthropic", "model", "claude-3"],
    "metadata": {
      "provider": "anthropic",
      "modelId": "claude-3-opus-20240229",
      "displayName": "Claude 3 Opus",
      "contextWindow": 200000,
      "maxOutputTokens": 4096,
      "inputPricePerMillion": 15.00,
      "outputPricePerMillion": 75.00,
      "supportedOperations": ["messages"],
      "capabilities": ["vision", "tool_use"]
    }
  },
  {
    "id": "int-huggingface-config",
    "key": "integrations/ai/huggingface/config",
    "name": "HuggingFace Provider Configuration",
    "description": "Configuration for HuggingFace Inference API",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "integration"],
    "accessPolicy": {
      "visibility": "public",
      "actions": {
        "read": { "anyOf": ["public"] },
        "write": { "anyOf": ["role:admin"] }
      }
    },
    "metadata": {
      "provider": "huggingface",
      "baseUrl": "https://router.huggingface.co",
      "authType": "bearer",
      "endpoints": {
        "chat.completions": "/v1/chat/completions",
        "text.generation": "/v1/chat/completions",
        "embeddings": "/v1/embeddings"
      },
      "rateLimits": {
        "requestsPerMinute": 30,
        "tokensPerMinute": 20000
      },
      "defaultModel": "meta-llama/Llama-3.2-3B-Instruct",
      "supportedOperations": ["text.generation", "chat.completions", "embeddings"],
      "note": "Uses OpenAI-compatible API format"
    }
  },
  {
    "id": "int-huggingface-llama32-3b",
    "key": "integrations/ai/huggingface/models/meta-llama/Llama-3.2-3B-Instruct",
    "name": "Llama 3.2 3B Instruct",
    "description": "Meta Llama 3.2 3B Instruct - efficient open model for basic tasks",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "llama", "open-source"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "meta-llama/Llama-3.2-3B-Instruct",
      "displayName": "Llama 3.2 3B Instruct",
      "contextWindow": 128000,
      "maxOutputTokens": 2048,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source"]
    }
  },
  {
    "id": "int-huggingface-llama31-70b",
    "key": "integrations/ai/huggingface/models/meta-llama/Llama-3.1-70B-Instruct",
    "name": "Llama 3.1 70B Instruct",
    "description": "Meta Llama 3.1 70B Instruct - powerful open model",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "llama", "open-source"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "meta-llama/Llama-3.1-70B-Instruct",
      "displayName": "Llama 3.1 70B Instruct",
      "contextWindow": 128000,
      "maxOutputTokens": 4096,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source", "tool_use"]
    }
  },
  {
    "id": "int-huggingface-llama33-70b",
    "key": "integrations/ai/huggingface/models/meta-llama/Llama-3.3-70B-Instruct",
    "name": "Llama 3.3 70B Instruct",
    "description": "Meta Llama 3.3 70B Instruct - latest and most capable Llama",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "llama", "open-source"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "meta-llama/Llama-3.3-70B-Instruct",
      "displayName": "Llama 3.3 70B Instruct",
      "contextWindow": 128000,
      "maxOutputTokens": 4096,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source", "tool_use"]
    }
  },
  {
    "id": "int-huggingface-mistral-7b",
    "key": "integrations/ai/huggingface/models/mistralai/Mistral-7B-Instruct-v0.3",
    "name": "Mistral 7B Instruct v0.3",
    "description": "Mistral AI 7B Instruct v0.3 - efficient model for general tasks",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "mistral", "open-source"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "mistralai/Mistral-7B-Instruct-v0.3",
      "displayName": "Mistral 7B Instruct v0.3",
      "contextWindow": 32768,
      "maxOutputTokens": 4096,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source"]
    }
  },
  {
    "id": "int-huggingface-qwen25-72b",
    "key": "integrations/ai/huggingface/models/Qwen/Qwen2.5-72B-Instruct",
    "name": "Qwen 2.5 72B Instruct",
    "description": "Alibaba Qwen 2.5 72B Instruct - high capability open model",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "qwen", "open-source"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "Qwen/Qwen2.5-72B-Instruct",
      "displayName": "Qwen 2.5 72B Instruct",
      "contextWindow": 131072,
      "maxOutputTokens": 8192,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source", "tool_use"]
    }
  },
  {
    "id": "int-huggingface-deepseek-r1",
    "key": "integrations/ai/huggingface/models/deepseek-ai/DeepSeek-R1",
    "name": "DeepSeek R1",
    "description": "DeepSeek R1 - reasoning-focused open model",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["ai", "llm", "huggingface", "model", "deepseek", "open-source", "reasoning"],
    "metadata": {
      "provider": "huggingface",
      "modelId": "deepseek-ai/DeepSeek-R1",
      "displayName": "DeepSeek R1",
      "contextWindow": 128000,
      "maxOutputTokens": 8192,
      "supportedOperations": ["text.generation", "chat.completions"],
      "capabilities": ["open_source", "reasoning"]
    }
  },
  {
    "id": "int-telegram-bot-api",
    "key": "telegram",
    "name": "Telegram Bot API",
    "description": "Telegram Bot API for messaging, media, and bot management",
    "type": "integration",
    "status": "published",
    "isBootstrap": true,
    "tags": ["channel", "telegram", "messaging", "bot", "openapi"],
    "accessPolicy": {
      "visibility": "public",
      "actions": {
        "read": { "anyOf": ["public"] },
        "write": { "anyOf": ["role:admin"] }
      }
    },
    "metadata": {
      "integrationType": "openapi",
      "specUrl": "https://raw.githubusercontent.com/sys-001/telegram-bot-api-versions/main/files/openapi/yaml/v230.yaml",
      "serverUrl": "https://api.telegram.org/bot{token}",
      "authType": "path",
      "channelType": "telegram",
      "connectionMode": "webhook",
      "capabilities": {
        "directMessages": true,
        "groupChats": true,
        "threads": false,
        "reactions": true,
        "fileAttachments": true,
        "voiceMessages": true,
        "edits": true,
        "deletions": true,
        "typing": true,
        "readReceipts": false
      },
      "formatting": {
        "maxLength": 4096,
        "supportsMarkdown": true,
        "supportsHtml": true,
        "supportsMentions": true,
        "supportsEmoji": true
      },
      "operations": "auto-discover"
    }
  }
]
